{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación usando SVM y Bag of Words con descriptores SIFT\n",
    "\n",
    "Del capítulo 7 de J.Howse et al. \"Learning OpenCV 4 Computer Vision with Python 3\" (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_and_neg_paths(i):\n",
    "    pos_path = 'images/car/train/pos-%d.pgm' % (i+1) # Imagen de carro (+)\n",
    "    neg_path = 'images/car/train/neg-%d.pgm' % (i+1) # Imagen de no carro \n",
    "    return pos_path, neg_path\n",
    "\n",
    "def add_sample(path):\n",
    "    # Lectura de la imagen\n",
    "    I = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Extracción de descriptores SIFT\n",
    "    keypoints, descriptores = sift.detectAndCompute(I, None)\n",
    "    # Añadir descriptores al entrenador de vocabulario de BoW\n",
    "    if descriptores is not None:\n",
    "        bow_kmeans_trainer.add(descriptores)\n",
    "\n",
    "def extract_bow_descriptors(img):\n",
    "    # Toma una imagen y devuelve su vector descriptor de BoW\n",
    "    features = sift.detect(img)\n",
    "    return bow_extractor.compute(img, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de imágenes de muestra para Bag of Words\n",
    "BOW_NUM_TRAINING_SAMPLES_PER_CLASS = 10\n",
    "# Número de descriptores BoW para SVM\n",
    "SVM_NUM_TRAINING_SAMPLES_PER_CLASS = 100\n",
    "\n",
    "# Instancia del descriptor SIFT\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# Uso de FLANN para encontrar las correspondencias\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = {}\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto que entrena un vocabulario de Bag of Words (40 clústeres)\n",
    "bow_kmeans_trainer = cv2.BOWKMeansTrainer(40)\n",
    "# Objeto para convertir descriptores SIFT en BoW\n",
    "bow_extractor = cv2.BOWImgDescriptorExtractor(sift, flann)\n",
    "\n",
    "# Bucle para algunas imágenes de entrenamiento\n",
    "for i in range(BOW_NUM_TRAINING_SAMPLES_PER_CLASS):\n",
    "    pos_path, neg_path = get_pos_and_neg_paths(i)\n",
    "    add_sample(pos_path)\n",
    "    add_sample(neg_path)\n",
    "\n",
    "# Clusterización usando K-means. Retorna el vocabulario.\n",
    "voc = bow_kmeans_trainer.cluster()\n",
    "bow_extractor.setVocabulary(voc)\n",
    "\n",
    "# Extracción de descriptores BoW\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for i in range(SVM_NUM_TRAINING_SAMPLES_PER_CLASS):\n",
    "    pos_path, neg_path = get_pos_and_neg_paths(i)\n",
    "    pos_img = cv2.imread(pos_path, cv2.IMREAD_GRAYSCALE)\n",
    "    pos_descriptors = extract_bow_descriptors(pos_img)\n",
    "    if pos_descriptors is not None:\n",
    "        training_data.extend(pos_descriptors)\n",
    "        training_labels.append(1)\n",
    "    neg_img = cv2.imread(neg_path, cv2.IMREAD_GRAYSCALE)\n",
    "    neg_descriptors = extract_bow_descriptors(neg_img)\n",
    "    if neg_descriptors is not None:\n",
    "        training_data.extend(neg_descriptors)\n",
    "        training_labels.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(bow_extractor)  # Atributos del objeto \"bow_extractor\"\n",
    "\n",
    "# Número de elementos de \"box_extractor\": 40 clústeres (cada uno con un vector SIFT de 128 elementos)\n",
    "bow_extractor.getVocabulary().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de datos de entrenamiento: 200\n",
      "Tamaño de cada elemento de entrenamiento: (40,)\n"
     ]
    }
   ],
   "source": [
    "# Números de elementos de entrenamiento\n",
    "print(\"Número de datos de entrenamiento:\" , len(training_data))\n",
    "print(\"Tamaño de cada elemento de entrenamiento:\",  training_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de un SVM\n",
    "svm = cv2.ml.SVM_create()\n",
    "# Entrenamiento del SVM\n",
    "svm.train(np.array(training_data), cv2.ml.ROW_SAMPLE, np.array(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de imágenes de prueba\n",
    "lista_imagenes = ['images/car/test/test-0.pgm',\n",
    "                  'images/car/test/test-1.pgm',\n",
    "                  'images/car.jpg',\n",
    "                  'images/campo.jpg',\n",
    "                  'images/statue.jpg',\n",
    "                  'images/woodcutters.jpg']\n",
    "\n",
    "for test_img_path in lista_imagenes:\n",
    "    img = cv2.imread(test_img_path)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    descriptors = extract_bow_descriptors(gray_img)\n",
    "    prediction = svm.predict(descriptors)\n",
    "    if prediction[1][0][0] == 1.0:\n",
    "        text = 'Es auto'\n",
    "        color = (0, 255, 0)\n",
    "    else:\n",
    "        text = 'No es auto'\n",
    "        color = (0, 0, 255)\n",
    "    cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                color, 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Se abrirá una nueva ventana (presionar cualquier tecla para continuar)\n",
    "    cv2.imshow(test_img_path, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
