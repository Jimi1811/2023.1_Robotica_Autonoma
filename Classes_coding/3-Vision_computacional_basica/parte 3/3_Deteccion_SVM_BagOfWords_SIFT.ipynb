{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de autos usando SVM y Bag of Words con descriptores SIFT\n",
    "\n",
    "Del capítulo 7 de J.Howse et al. \"Learning OpenCV 4 Computer Vision with Python 3\" (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malisiewicz et al. Python port by Adrian Rosebrock\n",
    "# https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "\n",
    "# Non maximum suppression (fast)\n",
    "def nms(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # initialize the list of picked indexes \n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    scores = boxes[:,4]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the score/probability of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(scores)[::-1]\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                                               np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return only the bounding boxes that were picked\n",
    "    return boxes[pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_and_neg_paths(i):\n",
    "    pos_path = 'images/car/train/pos-%d.pgm' % (i+1)\n",
    "    neg_path = 'images/car/train/neg-%d.pgm' % (i+1)\n",
    "    return pos_path, neg_path\n",
    "\n",
    "def add_sample(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    if descriptors is not None:\n",
    "        bow_kmeans_trainer.add(descriptors)\n",
    "        \n",
    "def extract_bow_descriptors(img):\n",
    "    features = sift.detect(img)\n",
    "    return bow_extractor.compute(img, features)\n",
    "\n",
    "def pyramid(img, scale_factor=1.25, min_size=(200, 80),\n",
    "            max_size=(600, 600)):\n",
    "    h, w = img.shape\n",
    "    min_w, min_h = min_size\n",
    "    max_w, max_h = max_size\n",
    "    while w >= min_w and h >= min_h:\n",
    "        if w <= max_w and h <= max_h:\n",
    "            yield img\n",
    "        w /= scale_factor\n",
    "        h /= scale_factor\n",
    "        img = cv2.resize(img, (int(w), int(h)),\n",
    "                         interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def sliding_window(img, step=20, window_size=(100, 40)):\n",
    "    img_h, img_w = img.shape\n",
    "    window_w, window_h = window_size\n",
    "    for y in range(0, img_w, step):\n",
    "        for x in range(0, img_h, step):\n",
    "            roi = img[y:y+window_h, x:x+window_w]\n",
    "            roi_h, roi_w = roi.shape\n",
    "            if roi_w == window_w and roi_h == window_h:\n",
    "                yield (x, y, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_NUM_TRAINING_SAMPLES_PER_CLASS = 10\n",
    "SVM_NUM_TRAINING_SAMPLES_PER_CLASS = 100\n",
    "\n",
    "SVM_SCORE_THRESHOLD = 1.8\n",
    "NMS_OVERLAP_THRESHOLD = 0.15\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = {}\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_kmeans_trainer = cv2.BOWKMeansTrainer(12)\n",
    "bow_extractor = cv2.BOWImgDescriptorExtractor(sift, flann)\n",
    "\n",
    "for i in range(BOW_NUM_TRAINING_SAMPLES_PER_CLASS):\n",
    "    pos_path, neg_path = get_pos_and_neg_paths(i)\n",
    "    add_sample(pos_path)\n",
    "    add_sample(neg_path)\n",
    "    \n",
    "voc = bow_kmeans_trainer.cluster()\n",
    "bow_extractor.setVocabulary(voc)    \n",
    "\n",
    "training_data = []\n",
    "training_labels = []\n",
    "for i in range(SVM_NUM_TRAINING_SAMPLES_PER_CLASS):\n",
    "    pos_path, neg_path = get_pos_and_neg_paths(i)\n",
    "    pos_img = cv2.imread(pos_path, cv2.IMREAD_GRAYSCALE)\n",
    "    pos_descriptors = extract_bow_descriptors(pos_img)\n",
    "    if pos_descriptors is not None:\n",
    "        training_data.extend(pos_descriptors)\n",
    "        training_labels.append(1)\n",
    "    neg_img = cv2.imread(neg_path, cv2.IMREAD_GRAYSCALE)\n",
    "    neg_descriptors = extract_bow_descriptors(neg_img)\n",
    "    if neg_descriptors is not None:\n",
    "        training_data.extend(neg_descriptors)\n",
    "        training_labels.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setC(50)\n",
    "svm.train(np.array(training_data), cv2.ml.ROW_SAMPLE,\n",
    "          np.array(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img = ['images/car/test/test-1.pgm',\n",
    "            'images/car/test/test-7.pgm',\n",
    "            'images/car.jpg',\n",
    "            'images/woodcutters.jpg']\n",
    "\n",
    "for test_img_path in list_img:\n",
    "    img = cv2.imread(test_img_path)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    pos_rects = []\n",
    "    for resized in pyramid(gray_img):\n",
    "        for x, y, roi in sliding_window(resized):\n",
    "            descriptors = extract_bow_descriptors(roi)\n",
    "            if descriptors is None:\n",
    "                continue\n",
    "            prediction = svm.predict(descriptors)\n",
    "            if prediction[1][0][0] == 1.0:\n",
    "                raw_prediction = svm.predict(\n",
    "                    descriptors, flags=cv2.ml.STAT_MODEL_RAW_OUTPUT)\n",
    "                score = -raw_prediction[1][0][0]\n",
    "                if score > SVM_SCORE_THRESHOLD:\n",
    "                    h, w = roi.shape\n",
    "                    scale = gray_img.shape[0] / float(resized.shape[0])\n",
    "                    pos_rects.append([int(x * scale),\n",
    "                                      int(y * scale),\n",
    "                                      int((x+w) * scale),\n",
    "                                      int((y+h) * scale),\n",
    "                                      score])\n",
    "    pos_rects = nms(np.array(pos_rects), NMS_OVERLAP_THRESHOLD)\n",
    "    for x0, y0, x1, y1, score in pos_rects:\n",
    "        cv2.rectangle(img, (int(x0), int(y0)), (int(x1), int(y1)),\n",
    "                      (0, 255, 255), 2)\n",
    "        text = '%.2f' % score\n",
    "        cv2.putText(img, text, (int(x0), int(y0) - 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "    cv2.imshow(test_img_path, img)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
